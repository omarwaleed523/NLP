{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "986460c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data columns: ['tweet,sarcasm,sentiment,dialect']\n",
      "Testing data columns: ['tweet,sarcasm,sentiment,dialect']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "# Function to clean Arabic text\n",
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    # Remove emojis (this is a basic approach)\n",
    "    text = re.sub(r'[^\\w\\s,.]', ' ', text)\n",
    "    # Remove extra spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    # Remove leading/trailing spaces\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "# Load the datasets correctly with proper delimiter\n",
    "try:\n",
    "    # First attempt with tab delimiter\n",
    "    train_df = pd.read_csv('train-data-final.csv', sep='\\t')\n",
    "    test_df = pd.read_csv('testing-data-final.csv', sep='\\t')\n",
    "except:\n",
    "    # If that fails, try comma delimiter\n",
    "    train_df = pd.read_csv('train-data-final.csv')\n",
    "    test_df = pd.read_csv('testing-data-final.csv')\n",
    "\n",
    "# Display the columns to check if they were parsed correctly\n",
    "print(\"Training data columns:\", train_df.columns.tolist())\n",
    "print(\"Testing data columns:\", test_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "778fa50b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\omarw\\AppData\\Local\\Temp\\ipykernel_37672\\4163548638.py:13: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  parts = row[0].split(',')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data columns after fix: ['tweet', 'sarcasm', 'sentiment', 'dialect']\n",
      "Testing data columns after fix: ['tweet', 'sarcasm', 'sentiment', 'dialect']\n",
      "\n",
      "Training data sample:\n",
      "                                               tweet sarcasm sentiment dialect\n",
      "0  د محمودالعلايليأرى أن الفريق أحمدشفيق رقم مهم ...   FALSE       NEU     msa\n",
      "1                          مع فيدرر يا آجا والكبار     FALSE       NEU     msa\n",
      "\n",
      "Testing data sample:\n",
      "                                               tweet sarcasm sentiment dialect\n",
      "0  اخوي حانق يالغلا وشفيك معصب؟ عادي تراهم بشر يف...   FALSE       NEG     msa\n",
      "1                            اف مو متعوده عليهم سته     TRUE       NEG     msa\n"
     ]
    }
   ],
   "source": [
    "# If the data is still not parsed correctly (only one column),\n",
    "# let's fix the parsing issue\n",
    "def fix_parsing(df):\n",
    "    if len(df.columns) == 1 and 'tweet,sarcasm,sentiment,dialect' in df.columns:\n",
    "        # The header is in the column name, and data is not properly split\n",
    "        # First, get the correct column names\n",
    "        column_names = df.columns[0].split(',')\n",
    "        \n",
    "        # Create a new DataFrame with the correct structure\n",
    "        rows = []\n",
    "        for _, row in df.iterrows():\n",
    "            # Split each row by comma, but be careful with text that may contain commas\n",
    "            parts = row[0].split(',')\n",
    "            # The tweet might contain commas, so join all except the last 3 parts\n",
    "            if len(parts) > 3:\n",
    "                tweet = ','.join(parts[:-3])\n",
    "                sarcasm = parts[-3]\n",
    "                sentiment = parts[-2]\n",
    "                dialect = parts[-1]\n",
    "                rows.append([tweet, sarcasm, sentiment, dialect])\n",
    "            else:\n",
    "                # If row doesn't have enough parts, add it as is\n",
    "                rows.append(parts + [''] * (4 - len(parts)))\n",
    "        \n",
    "        return pd.DataFrame(rows, columns=column_names)\n",
    "    return df\n",
    "\n",
    "# Apply the fix if needed\n",
    "train_df = fix_parsing(train_df)\n",
    "test_df = fix_parsing(test_df)\n",
    "\n",
    "# Check if the fix worked\n",
    "print(\"Training data columns after fix:\", train_df.columns.tolist())\n",
    "print(\"Testing data columns after fix:\", test_df.columns.tolist())\n",
    "\n",
    "# Display a few rows to verify\n",
    "print(\"\\nTraining data sample:\")\n",
    "print(train_df.head(2))\n",
    "print(\"\\nTesting data sample:\")\n",
    "print(test_df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db85ea54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in training data:\n",
      " tweet        0\n",
      "sarcasm      0\n",
      "sentiment    0\n",
      "dialect      0\n",
      "dtype: int64\n",
      "Missing values in testing data:\n",
      " tweet        0\n",
      "sarcasm      0\n",
      "sentiment    0\n",
      "dialect      0\n",
      "dtype: int64\n",
      "\n",
      "Training data shape: (12549, 4)\n",
      "Testing data shape: (3000, 4)\n"
     ]
    }
   ],
   "source": [
    "# Clean the text data\n",
    "train_df['tweet'] = train_df['tweet'].apply(clean_text)\n",
    "test_df['tweet'] = test_df['tweet'].apply(clean_text)\n",
    "\n",
    "# Convert boolean strings to actual boolean values\n",
    "def convert_boolean(value):\n",
    "    if isinstance(value, str):\n",
    "        return value.upper() == 'TRUE'\n",
    "    return bool(value)\n",
    "\n",
    "train_df['sarcasm'] = train_df['sarcasm'].apply(convert_boolean)\n",
    "test_df['sarcasm'] = test_df['sarcasm'].apply(convert_boolean)\n",
    "\n",
    "# Check for missing values\n",
    "print(\"Missing values in training data:\\n\", train_df.isnull().sum())\n",
    "print(\"Missing values in testing data:\\n\", test_df.isnull().sum())\n",
    "\n",
    "# Fill missing values\n",
    "train_df = train_df.fillna({'tweet': '', 'sarcasm': False, 'sentiment': 'NEU', 'dialect': 'msa'})\n",
    "test_df = test_df.fillna({'tweet': '', 'sarcasm': False, 'sentiment': 'NEU', 'dialect': 'msa'})\n",
    "\n",
    "# Check data shapes\n",
    "print(\"\\nTraining data shape:\", train_df.shape)\n",
    "print(\"Testing data shape:\", test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d61d6e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 12549 examples to arsarcasm_train.json\n",
      "Saved 3000 examples to arsarcasm_test.json\n",
      "\n",
      "Example JSON format:\n",
      "{\n",
      "  \"input\": \"د محمودالعلايليأرى أن الفريق أحمدشفيق رقم مهم في المعادلة السياسية المصرية ولا يمكن إغفالههل ترى أن هذا صحيح أربعةزائدواحد\",\n",
      "  \"is_sarcastic\": false,\n",
      "  \"sentiment\": \"NEU\",\n",
      "  \"dialect\": \"msa\",\n",
      "  \"sarcasm_instruction\": \"Analyze if the given Arabic text contains sarcasm. Return ONLY 'TRUE' or 'FALSE' with no additional text or explanation.\",\n",
      "  \"sentiment_instruction\": \"Classify the sentiment of the given Arabic text. Return ONLY one of these labels: 'POS', 'NEG', or 'NEU' with no additional text or explanation.\",\n",
      "  \"dialect_instruction\": \"Identify the Arabic dialect in the given text. Return ONLY one of these labels: 'msa', 'egypt', 'gulf', 'levant', or 'magreb' with no additional text or explanation.\",\n",
      "  \"predicted_sarcasm\": \"\",\n",
      "  \"predicted_sentiment\": \"\",\n",
      "  \"predicted_dialect\": \"\"\n",
      "}\n",
      "Saved 3000 examples to arsarcasm_test.json\n",
      "\n",
      "Example JSON format:\n",
      "{\n",
      "  \"input\": \"د محمودالعلايليأرى أن الفريق أحمدشفيق رقم مهم في المعادلة السياسية المصرية ولا يمكن إغفالههل ترى أن هذا صحيح أربعةزائدواحد\",\n",
      "  \"is_sarcastic\": false,\n",
      "  \"sentiment\": \"NEU\",\n",
      "  \"dialect\": \"msa\",\n",
      "  \"sarcasm_instruction\": \"Analyze if the given Arabic text contains sarcasm. Return ONLY 'TRUE' or 'FALSE' with no additional text or explanation.\",\n",
      "  \"sentiment_instruction\": \"Classify the sentiment of the given Arabic text. Return ONLY one of these labels: 'POS', 'NEG', or 'NEU' with no additional text or explanation.\",\n",
      "  \"dialect_instruction\": \"Identify the Arabic dialect in the given text. Return ONLY one of these labels: 'msa', 'egypt', 'gulf', 'levant', or 'magreb' with no additional text or explanation.\",\n",
      "  \"predicted_sarcasm\": \"\",\n",
      "  \"predicted_sentiment\": \"\",\n",
      "  \"predicted_dialect\": \"\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Function to convert DataFrame to JSON format suitable for LLM fine-tuning\n",
    "def create_json_for_finetuning(df, output_file):\n",
    "    # Create a list to hold the formatted examples\n",
    "    json_data = []\n",
    "    \n",
    "    # Define the instructions for each task with very strict response formats\n",
    "    sarcasm_instruction = \"Analyze if the given Arabic text contains sarcasm. Return ONLY 'TRUE' or 'FALSE' with no additional text or explanation.\"\n",
    "    sentiment_instruction = \"Classify the sentiment of the given Arabic text. Return ONLY one of these labels: 'POS', 'NEG', or 'NEU' with no additional text or explanation.\"\n",
    "    dialect_instruction = \"Identify the Arabic dialect in the given text. Return ONLY one of these labels: 'msa', 'egypt', 'gulf', 'levant', or 'magreb' with no additional text or explanation.\"\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        # Create a sample with input (tweet) and output labels, along with instructions and predicted fields\n",
    "        sample = {\n",
    "            \"input\": row['tweet'],\n",
    "            \"is_sarcastic\": bool(row['sarcasm']),\n",
    "            \"sentiment\": row['sentiment'],\n",
    "            \"dialect\": row['dialect'],\n",
    "            \"sarcasm_instruction\": sarcasm_instruction,\n",
    "            \"sentiment_instruction\": sentiment_instruction,\n",
    "            \"dialect_instruction\": dialect_instruction,\n",
    "            \"predicted_sarcasm\": \"\",\n",
    "            \"predicted_sentiment\": \"\",\n",
    "            \"predicted_dialect\": \"\"\n",
    "        }\n",
    "        json_data.append(sample)\n",
    "    \n",
    "    # Write to JSON file\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(json_data, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    print(f\"Saved {len(json_data)} examples to {output_file}\")\n",
    "    return json_data\n",
    "\n",
    "# Convert to JSON and save\n",
    "train_json = create_json_for_finetuning(train_df, 'arsarcasm_train.json')\n",
    "test_json = create_json_for_finetuning(test_df, 'arsarcasm_test.json')\n",
    "\n",
    "# Show an example of the JSON format\n",
    "print(\"\\nExample JSON format:\")\n",
    "print(json.dumps(train_json[0], ensure_ascii=False, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
